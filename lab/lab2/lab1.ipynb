{
	"metadata": {
		"kernelspec": {
			"name": "glue_pyspark",
			"display_name": "Glue PySpark",
			"language": "python"
		},
		"language_info": {
			"name": "Python_Glue_Session",
			"mimetype": "text/x-python",
			"codemirror_mode": {
				"name": "python",
				"version": 3
			},
			"pygments_lexer": "python3",
			"file_extension": ".py"
		}
	},
	"nbformat_minor": 4,
	"nbformat": 4,
	"cells": [
		{
			"cell_type": "markdown",
			"source": "# AWS Glue Studio Notebook\n##### You are now running a AWS Glue Studio notebook; To start using your notebook you need to start an AWS Glue Interactive Session.\n",
			"metadata": {
				"editable": true
			}
		},
		{
			"cell_type": "code",
			"source": "from pyspark import SparkContext\nfrom pyspark.sql import SQLContext, Row, SparkSession\nfrom pyspark.sql import functions as F\n\n# 创建SparkSession对象\nspark = SparkSession.builder \\\n    .appName(\"Lab\") \\\n    .getOrCreate()\n\n## 创建SparkSession对象，然后调用里面的SparkContext方法读取text文件（如果想使用rdd转换为dataframe，\n## 需要先用rdd读入文件处理，再使用spark.createDataFrame转换为DataFrame。）",
			"metadata": {
				"trusted": true
			},
			"execution_count": 3,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "## 这里使用spark.sparkContext.textFile读入text文件并载入为rdd\n## 记得之后更换地址和文件名\n\ntemperature_file = spark.sparkContext.textFile(\"s3://bigdatalabs7051/data/temperature-readings-small/temperature-readings-small.csv\")\nlines = temperature_file.map(lambda line: line.split(\";\"))\n\n# (key, value) = (year,temperature)\ntempReadings = lines.map(lambda p: Row(station=p[0],\n                                       date=p[1],\n                                       year=p[1].split(\"-\")[0],\n                                       time=p[2],\n                                       value=float(p[3]),\n                                       quality=p[4]))\n\nschemaTempReadings = spark.createDataFrame(tempReadings)\n\n## 如果不用sql风格处理，不需要用schemaTempReadings.registerTempTable创建视图\n\nschemaTempReadings.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 8,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----------+-------+-------+--------+-----+----+\n|      date|quality|station|    time|value|year|\n+----------+-------+-------+--------+-----+----+\n|2013-11-01|      G| 102170|06:00:00|  6.8|2013|\n|2013-11-01|      G| 102170|18:00:00|  3.8|2013|\n|2013-11-02|      G| 102170|06:00:00|  5.8|2013|\n|2013-11-02|      G| 102170|18:00:00| -1.1|2013|\n|2013-11-03|      G| 102170|06:00:00| -0.2|2013|\n|2013-11-03|      G| 102170|18:00:00|  5.6|2013|\n|2013-11-04|      G| 102170|06:00:00|  6.5|2013|\n|2013-11-04|      G| 102170|18:00:00|  5.1|2013|\n|2013-11-05|      G| 102170|06:00:00|  4.2|2013|\n|2013-11-05|      G| 102170|18:00:00|  3.2|2013|\n|2013-11-06|      G| 102170|06:00:00|  1.7|2013|\n|2013-11-06|      G| 102170|18:00:00|  0.9|2013|\n|2013-11-07|      G| 102170|06:00:00| -0.1|2013|\n|2013-11-07|      G| 102170|18:00:00|  0.1|2013|\n|2013-11-08|      G| 102170|06:00:00| -1.2|2013|\n|2013-11-08|      G| 102170|18:00:00|  5.3|2013|\n|2013-11-09|      G| 102170|06:00:00|  5.6|2013|\n|2013-11-09|      G| 102170|18:00:00|  3.8|2013|\n|2013-11-10|      G| 102170|06:00:00|  2.2|2013|\n|2013-11-10|      G| 102170|18:00:00| -1.7|2013|\n+----------+-------+-------+--------+-----+----+\nonly showing top 20 rows\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "TempMinByYearStation = schemaTempReadings.where((schemaTempReadings[\"year\"] >= 1950) & (schemaTempReadings[\"year\"] <= 2014)). \\\n    groupBy('year', 'station'). \\\n    agg(F.min('value').alias('annualMin')). \\\n    select('year', 'station', 'annualMin')\n    # orderBy(['annualMin'], ascending=[False])\n    \nTempMinByYearStation.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 9,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----+-------+---------+\n|year|station|annualMin|\n+----+-------+---------+\n|2014| 102170|    -24.3|\n|2013| 102170|    -13.3|\n+----+-------+---------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# TempMinByYear = schemaTempReadings.groupBy('year'). \\\n#     agg(F.min('annualMin').alias('annualMin'))\n\n## schemaTempReadings中没有annualMin列，我猜你是想用TempMinByYearStation表\n\nTempMinByYear = TempMinByYearStation.groupBy('year'). \\\n    agg(F.min('annualMin').alias('annualMin'))\nTempMinByYear.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 12,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----+---------+\n|year|annualMin|\n+----+---------+\n|2014|    -24.3|\n|2013|    -13.3|\n+----+---------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# TempMinByYearWithStation = TempMinByYearStation.join(TempMinByYear, on=['year', 'annualMin'])\\\n#     .groupBy('year', 'annualMin')\\\n#     .select('year', 'station', 'annualMin')\\\n#     .orderBy(['annualMin'], ascending=[False])\n\nTempMinByYearWithStation = TempMinByYearStation.join(TempMinByYear, on=['year', 'annualMin'])\\\n    .select('year', 'station', 'annualMin')\\\n    .orderBy(['annualMin'], ascending=[False])\n\nTempMinByYearWithStation.show()\n\n## 记得遵循语句顺序，先select再groupBy,然后聚合\n## 这里为什么要用groupBy？",
			"metadata": {
				"trusted": true
			},
			"execution_count": 21,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----+-------+---------+\n|year|station|annualMin|\n+----+-------+---------+\n|2013| 102170|    -13.3|\n|2014| 102170|    -24.3|\n+----+-------+---------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# ------max\nTempMaxByYearStation = schemaTempReadings.where((schemaTempReadings[\"year\"] >= 1950) & (schemaTempReadings[\"year\"] <= 2014)). \\\n    groupBy('year', 'station'). \\\n    agg(F.max('value').alias('annualMax')). \\\n    select('year', 'station', 'annualMax')\n    # orderBy(['annualMax'], ascending=[False])\n\nTempMaxByYear = TempMaxByYearStation.groupBy('year'). \\\n    agg(F.max('annualMax').alias('annualMax'))\n\nTempMaxByYearWithStation = TempMaxByYearStation.join(TempMaxByYear, on=['year', 'annualMax'])\\\n    .select('year', 'station', 'annualMax')\\\n    .orderBy(['annualMax'], ascending=[False])\n\nTempMaxByYearWithStation.show()",
			"metadata": {
				"trusted": true
			},
			"execution_count": 27,
			"outputs": [
				{
					"name": "stdout",
					"text": "+----+-------+---------+\n|year|station|annualMax|\n+----+-------+---------+\n|2014| 102170|     29.1|\n|2013| 102170|     10.2|\n+----+-------+---------+\n",
					"output_type": "stream"
				}
			]
		},
		{
			"cell_type": "code",
			"source": "# Following code will save the result into /user/ACCOUNT_NAME/BDA/output folder\n\n## 你可以存储为csv文件，存储表格比rdd更方便\n\nTempMaxByYearWithStation.write.mode(\"overwrite\").format(\"csv\").save(\"s3://bigdatalabs7051/lab2/lab2012\")\nTempMinByYearWithStation.write.mode(\"overwrite\").format(\"csv\").save(\"s3://bigdatalabs7051/lab2/lab2011\")",
			"metadata": {
				"trusted": true
			},
			"execution_count": 28,
			"outputs": [
				{
					"name": "stdout",
					"text": "\n",
					"output_type": "stream"
				}
			]
		}
	]
}